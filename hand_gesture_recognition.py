# -*- coding: utf-8 -*-
"""Hand_Gesture_Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TukS3lFmDs28PRInOEj4HEGVl0RmN8Q7

**Setup: Install & Imports**
"""

!pip -q install kagglehub opencv-python tensorflow seaborn matplotlib scikit-learn

import os, glob, random, itertools, time, json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2

import kagglehub
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks

np.random.seed(42)
tf.random.set_seed(42)

"""**Download data**"""

path = kagglehub.dataset_download("gti-upm/leapgestrecog")
print("Dataset downloaded to:", path)

"""**Discover data**"""

def discover_images(root):
    """
    Walks the dataset and returns (file_path, class_label) pairs.
    Class label is taken from the gesture directory name like '01_palm'.
    """
    image_paths = []
    class_names = set()

    for person_dir in sorted(glob.glob(os.path.join(root, "*"))):
        if not os.path.isdir(person_dir):
            continue
        for gesture_dir in sorted(glob.glob(os.path.join(person_dir, "*"))):
            if not os.path.isdir(gesture_dir):
                continue
            gesture = os.path.basename(gesture_dir)
            class_names.add(gesture)
            files = glob.glob(os.path.join(gesture_dir, "*.png"))
            for f in files:
                image_paths.append((f, gesture))
    class_names = sorted(list(class_names))
    return image_paths, class_names

candidate = os.path.join(path, "leapGestRecog")
root_dir = candidate if os.path.isdir(candidate) else path

pairs, classes = discover_images(root_dir)
print(f"Discovered {len(pairs)} images across {len(classes)} classes.")
print("Classes:", classes)

label2idx = {c:i for i,c in enumerate(classes)}
idx2label = {i:c for c,i in label2idx.items()}

"""**Class Distribution**"""

counts = {c:0 for c in classes}
for _, c in pairs:
    counts[c] += 1

plt.figure(figsize=(12,5))
sns.barplot(x=list(counts.keys()), y=list(counts.values()))
plt.xticks(rotation=45, ha='right')
plt.title("Class Distribution")
plt.xlabel("Gesture")
plt.ylabel("Image Count")
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
for i, c in enumerate(classes[:10]):  # show up to first 10 classes to keep grid readable

    sample_path = next(p for p,label in pairs if label==c)
    img = cv2.imread(sample_path, cv2.IMREAD_GRAYSCALE)
    plt.subplot(2, 5, i+1)
    plt.imshow(img, cmap='gray')
    plt.title(c)
    plt.axis('off')
plt.suptitle("Sample Gestures (One Per Class)", y=1.05, fontsize=14)
plt.tight_layout()
plt.show()

"""**Data Loading & Preprocessing**"""

IMG_SIZE = 128

def load_and_preprocess(img_path):

    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:

        img = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    img = img.astype(np.float32) / 255.0

    img = np.expand_dims(img, axis=-1)  # (H, W, 1)
    return img

all_images = []
all_labels = []

for f, c in pairs:
    all_images.append(load_and_preprocess(f))
    all_labels.append(label2idx[c])

X = np.stack(all_images, axis=0)  # (N, H, W, 1)
y = np.array(all_labels, dtype=np.int64)

print("X shape:", X.shape, "y shape:", y.shape)

"""**Train/Val/Test split**"""

X_train, X_tmp, y_train, y_tmp = train_test_split(
    X, y, test_size=0.30, stratify=y, random_state=42
)
X_val, X_test, y_val, y_test = train_test_split(
    X_tmp, y_tmp, test_size=0.50, stratify=y_tmp, random_state=42
)

print("Split sizes:", X_train.shape, X_val.shape, X_test.shape)

"""**Model Building**"""

num_classes = len(classes)

def build_model(input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=10):
    model = models.Sequential([
        layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPooling2D(2,2),

        layers.Conv2D(64, (3,3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(2,2),

        layers.Conv2D(128, (3,3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(2,2),

        layers.Dropout(0.25),
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.4),
        layers.Dense(num_classes, activation='softmax')
    ])
    return model

model = build_model(input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=num_classes)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.summary()

"""**Training**"""

from tensorflow.keras import callbacks

es = callbacks.EarlyStopping(
    monitor='val_accuracy',
    patience=3,
    restore_best_weights=True
)

rlr = callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=2,
    verbose=1
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=12,
    batch_size=64,
    callbacks=[es, rlr],
    verbose=1
)

def plot_history(hist):
    h = hist.history
    plt.figure(figsize=(12,4))

    plt.subplot(1,2,1)
    plt.plot(h['accuracy'], label='Train Acc')
    plt.plot(h['val_accuracy'], label='Val Acc')
    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')
    plt.legend()

    plt.subplot(1,2,2)
    plt.plot(h['loss'], label='Train Loss')
    plt.plot(h['val_loss'], label='Val Loss')
    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')
    plt.legend()
    plt.tight_layout()
    plt.show()

plot_history(history)

"""**Testing**"""

test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_acc*100:.2f}%  |  Test Loss: {test_loss:.4f}")

y_pred_probs = model.predict(X_test, verbose=0)
y_pred = np.argmax(y_pred_probs, axis=1)

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=classes))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=False, cmap='Blues',
            xticklabels=classes, yticklabels=classes)
plt.title("Confusion Matrix (Test)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""**Few test predictions**"""

def show_predictions_grid(Xs, y_true, y_hat, idx2label, n=10):
    n = min(n, len(Xs))
    sel = np.random.choice(len(Xs), size=n, replace=False)
    plt.figure(figsize=(12, 8))
    for i, s in enumerate(sel):
        plt.subplot(int(np.ceil(n/5)), 5, i+1)
        img = (Xs[s].squeeze() * 255).astype(np.uint8)
        plt.imshow(img, cmap='gray')
        t = idx2label[y_true[s]]
        p = idx2label[y_hat[s]]
        color = "green" if t==p else "red"
        plt.title(f"T:{t}\nP:{p}", color=color, fontsize=9)
        plt.axis('off')
    plt.tight_layout()
    plt.show()

show_predictions_grid(X_test, y_test, y_pred, idx2label, n=12)

"""**Save label map & model**"""

os.makedirs("export", exist_ok=True)
model.save("export/gesture_cnn.h5")
with open("export/labels.json", "w") as f:
    json.dump(idx2label, f)
print("Saved model to export/gesture_cnn.h5 and labels to export/labels.json")